命令之乐
========
| 目录                           | 主要命令             |
| ------------------------------ | -------------------- |
| 用cat进行拼接                  | cat                  |
| 录制并回放终端会话             | script、scriptreplay |
| 查找并列出文件                 | find                 |
| 玩转xargs                      | xargs                |
| 用tr进行转换                   | tr                   |
| 校验和与核实                   |                      |
| 加密工具与散列                 |                      |
| 行排序                         |                      |
| 临时文件命名与随机数           |                      |
| 分割文件与数据                 |                      |
| 根据扩展名切分文件名           |                      |
| 多个文件的重命名与移动         |                      |
| 拼写检查与词典操作             |                      |
| 交互输入自动化                 |                      |
| 利用并行进程加速命令执行       |                      |
| 检查目录以及其中的文件与子目录 |                      |

#### 用cat进行拼接

cat命令能够显示或拼接文件内容，不过它的能力远不止如此。比如说，cat能够将标准输
入数据与文件数据组合在一起。通常的做法是将stdin重定向到一个文件，然后再合并两个文件。
而cat命令一次就能搞定这些操作。接下来你会看到该命令的基本用法和高级用法

cat命令是一个经常会用到的简单命令，它本身表示conCATenate（拼接）



用cat读取文件内容的一般语法是：

```shell
$ cat file1 file2 file3 ... 
# 该命令将作为命令行参数的文件内容拼接在一起并将结果发送到stdout

# 打印单个文件的内容
$ cat file.txt
This is a line inside file.txt
This is the second line inside file.txt

# 打印多个文件的内容
$ cat one.txt two.txt
This line is from one.txt
This line is from two.txt 

# cat命令不仅可以读取文件、拼接数据，还能够从标准输入中读取
# 管道操作符可以将数据作为cat命令的标准输入：
OUTPUT_FROM_SOME COMMANDS | cat

# cat也可以将文件内容与终端输入拼接在一起
# 下面的命令将stdin和另一个文件中的数据组合在一起：
$ echo 'Text through stdin' | cat - file.txt
# 在上例中，-被作为stdin文本的文件名
```

补充内容

cat命令还有一些用于文件查看的选项。可以在终端会话中输入man cat来查看完整的选项
列表

1. 去掉多余的空白行

```shell
# 有时候文本文件中可能包含多处连续的空白行。如果你想删除这些额外的空白行，可以这样做：
$ cat -s file 

# 考虑下面的例子:
$ cat multi_blanks.txt
line 1
line 2


line 3

line 4

$ cat -s multi_blanks.txt #压缩相邻的空白行
line 1
line 2
line 3
line 4 
# 另外也可以用tr删除所有的空白行
```

2. 将制表符显示为^I

单从视觉上很难将制表符同连续的空格区分开。对于Python而言，制表符和空格是区别对待
的。在文本编辑器中，两者看起来差不多，但是解释器将其视为不同的缩进。仅仅在文本编辑器
中进行观察是很难发现这种错误的。cat有一个特性，可以将制表符识别出来。这有助于排查缩
进错误

用cat命令的-T选项能够将制表符标记成^I。例如：

```shell
$ cat file.py
def function():
    var = 5
    	next = 6
    third = 7
    
$ cat -T file.py
def function():
^Ivar = 5
^I^Inext = 6
^Ithird = 7^I
```

3. 行号

cat命令的-n选项会在输出的每一行内容之前加上行号。例如：

```shell
$ cat lines.txt
line
line
line

$ cat -n lines.txt
     1 line
     2 line
     3 line 
```

别担心，cat命令绝不会修改你的文件，它只是根据用户提供的选项在stdout中生成一个修改过的输出而已

可别尝试用重定向来覆盖输入文件

shell在打开输入文件之前会先创建新的输出文件

cat命令不允许使用相同的文件作为输入和重定向后的输出

利用管道并重定向输出会清空输入文件

```shell
$> echo "This will vanish" > myfile
$> cat -n myfile >myfile
cat: myfile: input file is output file

$> cat myfile | cat -n >myfile
$> ls -l myfile
-rw-rw-rw-. 1 user user 0 Aug 24 00:14 myfile ; # myfile为空文件
```

选项-n会为包括空行在内的所有行生成行号。如果你想跳过空白行，可以使用选项-b

#### 录制并回放终端会话

将屏幕会话录制成视频肯定有用，不过对于调试终端会话或是提供shell教程来说，视频有些
“杀鸡用牛刀”了

shell给出了另一种选择。script命令能够录制你的击键以及击键时机，并将输入和输出结
果保存在对应的文件中。scriptreplay命令可以回放会话

script和scriptreplay命令在绝大多数GNU/Linux发行版上都可以找到。你可以通过录制
终端会话来制作命令行技巧视频教程，也可以与他人分享会话记录文件，研究如何使用命令行完
成某项任务。你甚至可以调用其他解释器并录制发送给该解释器的击键。但你无法记录vi、emacs
或其他将字符映射到屏幕特定位置的应用程序



开始录制终端会话：

```shell
$ script -t 2> timing.log -a output.session 

# 完整的录制过程如下：
$ script -t 2> timing.log -a output.session 

# 演示tclsh
$ tclsh
% puts [expr 2 + 2] 
4
% exit
$ exit
```

注意，该攻略不适用于不支持单独将stderr重定向到文件的shell，比如csh shell

可以指定一个文件名作为script命令的参数。该文件将保存击键及命令结果。如果指定了
-t选项，script命令会把时序数据发送到stdout。可以将这些数据重定向到其他文件中
（timing.log），这样该文件中就记录了每次击键的时机以及输出信息。上面的例子中使用2>将
stderr重定向到了文件timing.log

利用文件timing.log和output.session，可以按照下面的方法回放命令执行过程：

```shell
$ scriptreplay timing.log output.session
# 播放命令序列及输出
```

#### 查找并列出文件

find是Unix/Linux命令行工具箱中最棒的工具之一。该命令在命令行和shell脚本编写方面都
能发挥功效。同cat和ls一样，find也包含大量特性，多数用户都没有发挥出它的最大威力。这
则攻略讨论了find的一些常用的查找功能

find命令的工作方式如下：沿着文件层次结构向下遍历，匹配符合条件的文件，执行相应
的操作。默认的操作是打印出文件和目录，这也可以使用-print选项来指定



要列出给定目录下所有的文件和子目录，可以采用下面的语法：

```shell
$ find base_path 

# bash_path可以是任意位置（例如/home/slynux），find会从该位置开始向下查找。例如：
$ find . -print
.history
Downloads
Downloads/tcl.fossil
Downloads/chapter2.doc
…
# . 指定当前目录，.. 指定父目录。这是Unix文件系统中的约定用法

# print选项使用\n（换行符）分隔输出的每个文件或目录名
# 而-print0选项则使用空字符'\0'来分隔
# -print0的主要用法是将包含换行符或空白字符的文件名传给xargs命令
# 随后会详细讨论xargs命令：

$> echo "test" > "file name"

$> find . -type f -print | xargs ls -l
ls: cannot access ./file: No such file or directory
ls: cannot access name: No such file or directory

$> find . -type f -print0 | xargs -0 ls -l
-rw-rw-rw-. 1 user group 5 Aug 24 15:00 ./file name 
```

补充内容

上面的例子演示了如何使用find列出文件层次中所有的文件和目录。find命令能够基于通
配符或正则表达式、目录树深度、文件日期、文件类型等条件查找文件

1. 根据文件名或正则表达式进行搜索

-name选项指定了待查找文件名的模式。这个模式可以是通配符，也可以是正则表达式。在
下面的例子中，'*.txt'能够匹配所有名字以.txt结尾的文件或目录

注意：\*.txt两边的单引号。shell会扩展没有引号或是出现在双引号（"）中的通配符。单引号能够阻止shell扩展\*.txt，使得该字符串能够原封不动地传给find命令

```SHELL
$ find /home/slynux -name '*.txt' -print 
```

find命令有一个选项-iname（忽略字母大小写），该选项的作用和-name类似，只不过在匹配名字时会忽略大小写。例如：

```shell
$ ls
example.txt EXAMPLE.txt file.txt

$ find . -iname "example*" -print
./example.txt
./EXAMPLE.txt 
```

find命令支持逻辑操作符。-a和-and选项可以执行逻辑与（AND）操作，-o和-or选项可以执行逻辑或（OR）操作

```shell
$ ls
new.txt some.jpg text.pdf stuff.png

$ find . \( -name '*.txt' -o -name '*.pdf' \) -print
./text.pdf
./new.txt

# 上面的命令会打印出所有的.txt和.pdf文件，因为这个find命令能够匹配所有这两类文件
# \(以及\)用于将 -name '*.txt' -o -name '*.pdf'视为一个整体
```

下面的命令演示了如何使用-and操作符选择名字以s开头且其中包含e的文件：

```shell
$ find . \( -name '*e*' -and -name 's*' \)
./some.jpg 
```

-path选项可以限制所匹配文件的路径及名称。例如：

```shell
$ find /home/users -path '*/slynux/*' -name '*.txt' -print

# 能够匹配文件/home/users/slynux/readme.txt，但无法匹配/home/users/slynux.txt
```

-regex选项和-path类似，只不过前者是基于正则表达式来匹配文件路径的

下面的命令可以匹配.py或.sh文件：

```shell
$ ls
new.PY next.jpg test.py script.sh

$ find . -regex '.*\.(py\|sh\)$'
./test.py
script.sh

# -iregex选项可以让正则表达式在匹配时忽略大小写
$ find . -iregex '.*\(\.py\|\.sh\)$'
./test.py
./new.PY
./script.sh 
```

2. 否定参数

find也可以用!排除匹配到的模式：

```shell
$ find . ! -name "*.txt" -print 

# 上面的find命令能够匹配所有不以.txt结尾的文件。该命令的运行结果如下：
$ ls
list.txt new.PY new.txt next.jpg test.py

$ find . ! -name "*.txt" -print
.
./next.jpg
./test.py
./new.PY
```

3. 基于目录深度的搜索

find命令在查找时会遍历完所有的子目录。默认情况下，find命令不会跟随符号链接。-L
选项可以强制其改变这种行为。但如果碰上了指向自身的链接，find命令就会陷入死循环中

-maxdepth和-mindepth选项可以限制find命令遍历的目录深度。这可以避免find命令没
完没了地查找

/proc文件系统中包含了系统与当前执行任务的信息。特定任务的目录层次相当深，其中还
有一些绕回到自身（loop back on themselves）的符号链接。系统中运行的每个进程在proc中都有
对应的子目录，其名称就是该进程的进程ID。这个目录下有一个叫作cwd的链接，指向进程的当
前工作目录



下面的例子展示了如何列出运行在含有文件bundlemaker.def的目录下的所有任务：

```shell
$ find -L /proc -maxdepth 1 -name 'bundlemaker.def' 2>/dev/null 
```

- -L选项告诉find命令跟随符号链接
- 从/proc目录开始查找
- -maxdepth 1将搜索范围仅限制在当前目录
- -name 'bundlemaker.def'指定待查找的文件
- 2>/dev/null将有关循环链接的错误信息发送到空设备中 

-mindepth选项类似于-maxdepth，不过它设置的是find开始进行查找的最小目录深度。
这个选项可以用来查找并打印那些距离起始路径至少有一定深度的文件。例如，打印出深度距离
当前目录至少两个子目录的所有名字以f开头的文件：

```shell
$ find . -mindepth 2 -name "f*" -print
./dir1/dir2/file1
./dir3/dir4/f2 
# 即使当前目录或dir1和dir3中包含以f开头的文件，它们也不会被打印出来
```

注意：-maxdepth和-mindepth应该在find命令中及早出现。如果作为靠后的选
项，有可能会影响到find的效率，因为它不得不进行一些不必要的检查。例如，
如果-maxdepth出现在-type之后，find首先会找出-type所指定的文件，然
后再在匹配的文件中过滤掉不符合指定深度的那些文件。但是如果反过来，在
-type之前指定目录深度，那么find就能够在找到所有符合指定深度的文件后，
再检查这些文件的类型，这才是最有效的搜索之道

4. 根据文件类型搜索

类Unix系统将一切都视为文件。文件具有不同的类型，例如普通文件、目录、字符设备、块
设备、符号链接、硬链接、套接字以及FIFO等

find命令可以使用-type选项对文件搜索进行过滤。借助这个选项，我们可以告诉find命
令只匹配指定类型的文件

```shell
# 只列出所有的目录（包括子目录）
$ find . -type d -print 

# 将文件和目录分别列出可不是件容易事。不过有了find就好办了
# 只列出普通文件
$ find . -type f -print 

# 只列出符号链接：
$ find . -type l -print 
```

find能够识别出的类型与参数

| 文件类型 | 类型参数 |
| -------- | -------- |
| 普通文件 | f        |
| 符号链接 | l        |
| 目录     | d        |
| 字符设备 | c        |
| 块设备   | b        |
| 套接字   | s        |
| FIFO     | p        |

5. 根据文件的时间戳进行搜索

Unix/Linux文件系统中的每一个文件都有3种时间戳，如下所示

- 访问时间（-atime）：用户最近一次访问文件的时间
- 修改时间（-mtime）：文件内容最后一次被修改的时间
- 变化时间（-ctime）：文件元数据（例如权限或所有权）最后一次改变的时间

Unix默认并不保存文件的创建时间。但有一些文件系统（ufs2、ext4、zfs、btrfs、jfs）会选择这么做。可以使用stat命令访问文件创建时间

鉴于有些应用程序通过先创建一个新文件，然后再删除原始文件的方法来修改文件，文件创建时间未必准确

-atime、-mtime和-ctime可作为find的时间选项。它们可以用整数值来指定天数。这些数字前面可以加上-或+。-表示小于，+表示大于

```shell
# 打印出在最近7天内被访问过的所有文件
$ find . -type f -atime -7 -print 

# 打印出恰好在7天前被访问过的所有文件
$ find . -type f -atime 7 -print 

# 打印出访问时间超过7天的所有文件
$ find . -type f -atime +7 -print

# -mtime选项会根据修改时间展开搜索，-ctime会根据变化时间展开搜索
```

-atime、-mtime以及-ctime都是以“天”为单位来计时的

find命令还支持以“分钟”为计时单位的选项。这些选项包括：

- -amin（访问时间）
- -mmin（修改时间）
- -cmin（变化时间）

```shell
# 打印出7分钟之前访问的所有文件
$ find . -type f -amin +7 -print 

# -newer选项可以指定一个用于比较修改时间的参考文件，然后找出比参考文件更新的（更近的修改时间）所有文件
# 例如，找出比file.txt修改时间更近的所有文件
$ find . -type f -newer file.txt -print 

# find命令的时间戳处理选项有助于编写系统备份和维护脚本
```

6. 基于文件大小的搜索

```shell
# 可以根据文件的大小展开搜索
# 大于2KB的文件
$ find . -type f -size +2k 

# 小于2KB的文件
$ find . -type f -size -2k

# 大小等于2KB的文件
$ find . -type f -size 2k 
```

除了k之外，还可以用其他文件大小单位

- b：块（512字节）
- c：字节
- w：字（2字节）
- k：千字节（1024字节）
- M：兆字节（1024K字节）
- G：吉字节（1024M字节）



7. 基于文件权限和所有权的匹配

```shell
# 也可以根据文件权限进行文件匹配。列出具有特定权限的文件
$ find . -type f -perm 644 -print
# 打印出权限为644的文件

# -perm选项指明find应该只匹配具有特定权限值的文件

# 以Apache Web服务器为例
# Web服务器上的PHP文件需要具有合适的执行权限
# 我们可以用下面的方法找出那些没有设置好执行权限的PHP文件
$ find . -type f -name "*.php" ! -perm 644 -print
PHP/custom.php

$ ls -l PHP/custom.php
-rw-rw-rw-. root root 513 Mar 13 2016 PHP/custom.php 

# 我们也可以根据文件的所有权进行搜索
# 用选项 -user USER就能够找出由某个特定用户所拥有的文件
# 参数USER可以是用户名或UID
# 例如，可以使用下面的命令打印出用户slynux拥有的所有文件：
$ find . -type f -user slynux -print 
```

8. 利用find执行相应操作

find命令能够对其所查找到的文件执行相应的操作。无论是删除文件或是执行任意的Linux命令都没有问题

```shell
# 删除匹配的文件
# find命令的-delete选项可以删除所匹配到的文件
# 下面的命令能够从当前目录中删除.swp文件：
$ find . -type f -name "*.swp" -delete 

# 执行命令
# 利用-exec选项，find命令可以结合其他命令使用

# find命令使用一对花括号{}代表文件名
# 在下面的例子中，对于每一个匹配的文件，find命令会将{}替换成相应的文件名并更改该文件的所有权
# 如果find命令找到了root所拥有的两个文件，那么它会将其所有者改为slynux
$ sudo find . -type f -user root -exec chown slynux {} \; 

# 注意该命令结尾的\;。必须对分号进行转义，否则shell会将其视为find命令的结束，而非chown命令的结束
```

注意：为每个匹配到的文件调用命令可是个不小的开销。如果指定的命令接受多个参数（如chown），你可以换用加号（+）作为命令的结尾。这样find会生成一份包含所有搜索结果的列表，然后将其作为指定命令的参数，一次性执行

```shell
# 另一个例子是将给定目录中的所有C程序文件拼接起来写入单个文件all_c_files.txt
# 各种实现方法如下
$ find . -type f -name '*.c' -exec cat {} \;>all_c_files.txt
$ find . -type f -name '*.c' -exec cat {} > all_c_files.txt \;
$ fine . -type f -name '*.c' -exec cat {} >all_c_files.txt + 

# 我们使用 > 操作符将来自find的数据重定向到all_c_files.txt文件，没有使用>>（追加）的原因是find命令的全部输出就只有一个数据流（stdin），而只有当多个数据流被追加到单个文件中时才有必要使用>>

# 下列命令可以将10天前的 .txt文件复制到OLD目录中
$ find . -type f -mtime +10 -name "*.txt" -exec cp {} OLD \; 
# find命令还可以采用类似的方法与其他命令结合使用
```

注意：我们无法在-exec选项中直接使用多个命令。该选项只能够接受单个命令，不过我们可以耍一个小花招。把多个命令写到一个 shell脚本中（例如command.sh），然后在-exec中使用这个脚本：

```shell
-exec ./commands.sh {} \; 

# -exec可以同printf搭配使用来生成输出信息。例如：
$ find . -type f -name "*.cnf" -exec printf "Config file: %s\n" {} \;
Config file: /etc/openvpn/easy-rsa/openssl-1.0.0.cnf
Config file: /etc/my.cnf 
```

9. 让find跳过特定的目录

在find的执行过程中，跳过某些子目录能够提升性能。例如，在版本控制系统（如Git）管
理的开发源代码树中查找特定文件时，文件系统的每个子目录里都会包含一个目录，该目录中保
存了和版本控制相关的信息。这些目录通常跟我们没什么关系，所以没必要去搜索它们

```shell
# 在搜索时排除某些文件或目录的技巧叫作修剪
# 下面的例子演示了如何使用-prune选项排除某些符合条件的文件
$ find devel/source_path -name '.git' -prune -o -type f -print 

# -name ".git" –prune是命令中负责进行修剪的部分，它指明了.git目录应该被排除在外
# -type f –print描述了要执行的操作
```

#### 玩转xargs

Unix命令可以从标准输入（stdin）或命令行参数中接收数据。之前的例子已经展示了如何
利用管道将一个命令的标准输出传入到另一个命令的标准输入

```shell
# 我们可以用别的方法来调用只能接受命令行参数的命令
# 最简单的方法就是使用反引号执行命令，然后将其输出作为命令行参数
$ gcc `find '*.c'` 

# 这种方法在很多情况下都管用，但是如果要处理的文件过多，你会看到一条可怕的错误信息：
# Argument list too long
# xargs命令可以解决这个问题

# xargs命令从stdin处读取一系列参数，然后使用这些参数来执行指定命令
# 它能将单行或多行输入文本转换成其他格式，例如单行变多行或是多行变单行
```

xargs命令应该紧跟在管道操作符之后。它使用标准输入作为主要的数据源，将从stdin中读取的数据作为指定命令的参数并执行该命令。下面的命令将在一组C语言源码文件中搜索字符串main：

```shell
ls *.c | xargs grep main 
```

xargs命令重新格式化stdin接收到的数据，再将其作为参数提供给指定命令

xargs默认会执行echo命令

和find命令的-exec选项相比，两者在很多方面都相似

```SHELL
# 将多行输入转换成单行输出
# xargs默认的echo命令可以用来将多行输入转换成单行输出
$ cat example.txt # 样例文件
1 2 3 4 5 6
7 8 9 10
11 12

$ cat example.txt | xargs
1 2 3 4 5 6 7 8 9 10 11 12 

# 将单行输入转换成多行输出
# xargs的-n选项可以限制每次调用命令时用到的参数个数 
# 下面的命令将输入分割成多行，每行N个元素
$ cat example.txt | xargs -n 3
1 2 3
4 5 6
7 8 9
10 11 12 
```

工作原理

xargs命令接受来自stdin的输入，将数据解析成单个元素，然后调用指定命令并将这些元
素作为该命令的参数。xargs默认使用空白字符分割输入并执行/bin/echo

如果文件或目录名中包含空格（甚至是换行）的话，使用空白字符来分割输入就会出现问题。
比如My Documents目录就会被解析成两个元素：My和Documents，而这两者均不存在

```shell
# 我们可以定义一个用来分隔参数的分隔符。-d选项可以为输入数据指定自定义的分隔符
$ echo "splitXsplit2Xsplit3Xsplit4" | xargs -d X
Split1 split2 split3 split4 
# 在上面的代码中，stdin中是一个包含了多个X字符的字符串。我们可以用–d选项将X定义为输入分隔符

# 结合-n选项，可以将输入分割成多行，每行包含两个单词
$ echo "splitXsplitXsplitXsplit" | xargs -d X -n 2
split split
split split 
```

xargs命令可以同find命令很好地结合在一起。find的输出可以通过管道传给xargs，由后
者执行-exec选项所无法处理的复杂操作。如果文件系统的有些文件名中包含空格，find命令的
-print0选项可以使用0（NULL）来分隔查找到的元素，然后再用xargs对应的-0选项进行解
析。下面的例子在Samba挂载的文件系统中搜索.docx文件，这些文件名中通常会包含大写字母和
空格。其中使用了grep找出内容中不包含image的文件：

```shell
$ find /smbMount -iname '*.docx' -print0 | xargs -0 grep -L image 
```

补充内容

1. 读取stdin，为命令传入格式化参数

```shell
# 下面是一个短小的脚本cecho，可以用来更好地理解xargs是如何提供命令行参数的

#!/bin/bash
#文件名: cecho.sh
echo $*'#'

# 当参数被传递给文件cecho.sh后，它会打印这些参数并以 #字符作为结尾。例如：
$ ./cecho.sh arg1 arg2
arg1 arg2 # 
```

这里有一个常见的问题

```shell
# 有一个包含着参数列表的文件（每行一个参数）要提供给某个命令（比如cecho.sh）
# 我需要以不同的形式来应用这些参数。在第一种形式中，每次调用提供一个参数
./cecho.sh arg1
./cecho.sh arg2
./cecho.sh arg3 

# 接下来，每次调用提供一到两个参数
./cecho.sh arg1 arg2
./cecho.sh arg3 

# 最后，在单次调用中提供所有参数
./cecho.sh arg1 arg2 arg3 

# 先别急着往下看，试着运行一下上面的命令，然后仔细观察输出结果
# xargs命令可以格式化参数，满足各种需求。args.txt文件中包含一个参数列表
$ cat args.txt
arg1
arg2
arg3 

# 对于第一种形式，我们需要多次执行指定的命令，每次执行时传入一个参数
# xargs的-n选项可以限制传入命令的参数个数
$ cat args.txt | xargs -n 1 ./cecho.sh
arg1 #
arg2 #
arg3 #

# 如果要将参数限制为2个，可以这样
$ cat args.txt | xargs -n 2 ./cecho.sh
arg1 arg2 #
arg3 #

# 最后，为了在执行命令时一次性提供所有的参数，选择不使用-n选项
$ cat args.txt | xargs ./cecho.sh
arg1 arg2 arg3 #

# 在上面的例子中，由xargs添加的参数都被放置在指定命令的尾部
# 但我们可能需要在命令末尾有一个固定的参数，并希望xargs能够替换居于中间位置的参数，就像这样
./cecho.sh -p arg1 -l 

# 在命令执行过程中，arg1是唯一的可变内容，其余部分都保持不变。args.txt中的参数是像这样提供给命令的
./cecho.sh -p arg1 -l
./cecho.sh -p arg2 -l
./cecho.sh -p arg3 -l 

# xargs有一个选项-I，可以用于指定替换字符串，这个字符串会在xargs解析输入时被参数替换掉
# 如果将-I与xargs结合使用，对于每一个参数，指定命令只会执行一次。来看看解决方法
$ cat args.txt | xargs -I {} ./cecho.sh -p {} -l
-p arg1 -l #
-p arg2 -l #
-p arg3 -l # 
# -I {}指定了替换字符串。为该命令提供的各个参数会通过stdin读取并依次替换掉字符串{}

# 使用-I的时候，命令以循环的方式执行。如果有3个参数，那么命令就会连同{}一起被执行3次。{}会在每次执行中被替换为相应的参数
```

2. 结合find使用xargs

```shell
# xargs和find可以配合完成任务。不过在结合使用的时候需要留心。考虑下面的例子：
$ find . -type f -name "*.txt" -print | xargs rm -f 

# 这样做很危险，有可能会误删文件。我们无法预测find命令输出的分隔符究竟是什么（究竟是'\n'还是' '）
# 如果有文件名中包含空格符（' '），xargs会将其误认为是分隔符。例如，bashrc text.txt会被视为bashrc和text.txt。因此上面的命令不会删除bashrc text.txt，而是会把bashrc删除

# 使用find命令的-print0选项生成以空字符（'\0'）作为分隔符的输出，然后将其作为xargs命令的输入

# 下列命令会查找并删除所有的.txt文件
$ find . -type f -name "*.txt" -print0 | xargs -0 rm -f 
```

3. 统计源代码目录中所有C程序文件的行数

大多数程序员在某一时刻都会统计自己的C程序文件的行数（Lines of Code，LOC）。完成这
项任务的代码如下：

```shell
$ find source_code_dir_path -type f -name "*.c" -print0 | xargs -0 wc –l 
```

如果你想获得更多有关源代码的统计信息，一个叫作SLOCCount的实用工具可以派上用场。现代GNU/Linux发行版一般都包含这个软件包，或者你也可以从http://www.dwheeler.com/sloccount/下载

4. 结合stdin，巧妙运用while语句和子shell

```shell
# xargs会将参数放置在指定命令的尾部，因此无法为多组命令提供参数
# 我们可以通过创建子shell来处理这种复杂情况
# 子shell利用while循环读取参数并执行命令，就像这样
$ cat files.txt | ( while read arg; do cat $arg; done )
# 等同于cat files.txt | xargs -I {} cat {} 

# 在while循环中，可以将cat $arg替换成任意数量的命令，这样我们就可以对同一个参数执行多条命令
# 也可以不借助管道将输出传递给其他命令
# 这种利用()创建子shell的技巧可以应用于各种问题场景
# 子shell操作符内部的多条命令在执行时就像一个整体，因此
$ cmd0 | ( cmd1;cmd2;cmd3) | cmd4 
# 如果cmd1是cd /，那么就会改变子shell工作目录，然而这种改变仅局限于该子shell内部
# cmd4则不受工作目录变化的影响

# shell的-c选项可以调用子shell来执行命令行脚本
# 它可以与xargs结合解决多次替换的问题
# 下列命令找出了所有的C文件并显示出每个文件的名字，文件名前会加上一个换行符（-e选项允许进行转义替换）
# 在文件名之后是该文件中含有main的所有行
find . -name '*.c' | xargs -I ^ sh -c "echo -ne '\n ^: '; grep main ^" 
```

#### 用tr进行转换

tr是Unix命令行专家工具箱中的一件万能工具。它可用于编写优雅的单行命令。tr可以对
来自标准输入的内容进行字符替换、字符删除以及重复字符压缩。tr是translate（转换）的简写，
因为它可以将一组字符转换成另一组字符。在这则攻略中，我们会看到如何使用tr进行基本的集
合转换

```shell
# tr只能通过stdin（标准输入）接收输入（无法通过命令行参数接收）。其调用格式如下
tr [options] set1 set2 

# 来自stdin的输入字符会按照位置从set1映射到set2（set1中的第一个字符映射到set2中的第一个字符，以此类推），然后将输出写入stdout（标准输出）
# set1和set2是字符类或字符组。如果两个字符组的长度不相等，那么set2会不断复制其最后一个字符，直到长度与set1相同
# 如果set2的长度大于set1，那么在set2中超出set1长度的那部分字符则全部被忽略
```

```shell
# 要将输入中的字符由大写转换成小写，可以使用下面的命令
$ echo "HELLO WHO IS THIS" | tr 'A-Z' 'a-z'
hello who is this 

# 'A-Z'和'a-z'都是字符组。我们可以按照需要追加字符或字符类来构造自己的字符组

# 'ABD-}'、'aA.,'、'a-ce-x'以及'a-c0-9'等均是合法的集合。定义集合也很简单，不需要书写一长串连续的字符序列，只需要使用“起始字符-终止字符”这种格式就行了。这种写法也可以和其他字符或字符类结合使用。如果“起始字符-终止字符”不是有效的连续字符序列，那么它就会被视为含有3个元素的集合（起始字符、-和终止字符）。你也可以使用像'\t'、'\n'这种特殊字符或其他ASCII字符
```

在tr中利用集合的概念，可以轻松地将字符从一个集合映射到另一个集合中。下面来看一个
用tr进行数字加密和解密的例子：

```shell
$ echo 12345 | tr '0-9' '9876543210'
87654 # 已加密

$ echo 87654 | tr '9876543210' '0-9'
12345 # 已解密

# tr命令可以用来加密
# ROT13是一个著名的加密算法。在ROT13算法中，字符会被移动13个位置，因此文本加密和解密都使用同一个函数
$ echo "tr came, tr saw, tr conquered." | tr 'a-zA-Z' 'n-za-mN-ZA-M' 
ge pnzr, ge fnj, ge pbadhrerq. 

# 对加密后的密文再次使用同样的ROT13函数，我们可以采用：
$ echo ge pnzr, ge fnj, ge pbadhrerq. | tr 'a-zA-Z' 'n-za-mN-ZA-M' 
tr came, tr saw, tr conquered. 

# tr还可以将制表符转换成单个空格
$ tr '\t' ' ' < file.txt 
```

补充内容

我们已经学习了tr的一些基本转换，接下来看看tr还能帮我们实现的其他功能

1. 用tr删除字符
```shell
# tr有一个选项-d，可以通过指定需要被删除的字符集合，将出现在stdin中的特定字符清除掉
$ cat file.txt | tr -d '[set1]'
#只使用set1，不使用set2 

$ echo "Hello 123 world 456" | tr -d '0-9'
Hello world
# 将stdin中的数字删除并打印删除后的结果
```
2. 字符组补集
```shell
# 我们可以利用选项-c来使用set1的补集。下面的命令中，set2是可选的
tr -c [set1] [set2] 

# 如果只给出了set1，那么tr会删除所有不在set1中的字符
# 如果也给出了set2，tr会将不在set1中的字符转换成set2中的字符
# 如果使用了-c选项，set1和set2必须都给出
# 如果-c与-d选项同时出现，你只能使用set1，其他所有的字符都会被删除

# 下面的例子会从输入文本中删除不在补集中的所有字符
$ echo hello 1 char 2 next 4 | tr -d -c '0-9 \n'
124

# 接下来的例子会将不在set1中的字符替换成空格：
$ echo hello 1 char 2 next 4 | tr -c '0-9' ' '
     1      2      4 
```
3. 用tr压缩字符
```shell
# tr命令能够完成很多文本处理任务。例如，它可以删除字符串中重复出现的字符。基本实现形式如下
tr -s '[需要被压缩的一组字符]' 

# 如果你习惯在点号后面放置两个空格，你需要在不删除重复字母的情况下去掉多余的空格
$ echo "GNU is      not     UNIX.  Recursive right ?" | tr -s ' '
GNU is not UNIX. Recursive right ? 

# tr命令还可以用来删除多余的换行符：
$ cat multi_blanks.txt | tr -s '\n'
line 1
line 2
line 3
line 4 

# 上面的例子展示了如何使用tr删除多余的'\n'字符

# 接下来让我们用tr以一种巧妙的方式将文件中的数字列表进行相加
$ cat sum.txt
1
2
3
4
5

$ cat sum.txt | echo $[ $(tr '\n' '+' ) 0 ]
15 
# 这招是如何起效的？
# 在命令中，tr命令将'\n'替换成了'+'，我们因此得到了字符串1+2+3+..5+，但是在字符串的尾部多了一个操作符+
# 为了抵消这个多出来的操作符，我们再追加一个0

# $[ operation ]执行算术运算，因此就形成了以下命令
echo $[ 1+2+3+4+5+0 ] 

# 如果我们利用循环从文件中读取数字，然后再进行相加，那肯定得用几行代码。有了tr，只用一行就搞定了

# 如果有一个包含字母和数字的文件，我们想计算其中的数字之和，这需要更强的技巧性
$ cat test.txt
first 1
second 2
third 3 

# 利用tr的-d选项删除文件中的字母，然后将空格替换成+
$ cat test.txt | tr -d [a-z] | echo "total: $[$(tr ' ' '+')]"
total: 6 
```

4. 字符类

tr可以将不同的字符类作为集合使用，所支持的字符类如下所示

- alnum：字母和数字
- alpha：字母
- cntrl：控制（非打印）字符
- digit：数字
- graph：图形字符
- lower：小写字母
- print：可打印字符
- punct：标点符号
- space：空白字符
- upper：大写字母
- xdigit：十六进制字符

可以按照下面的方式选择所需的字符类：

```shell
tr [:class:] [:class:]

tr '[:lower:]' '[:upper:]' 
```

#### 校验和与核实

Unix和Linux支持多种校验和程序，但强健性最好且使用最为广泛的校验和算法是MD5和
SHA-1。md5sum和sha1sum程序可以对数据应用对应的算法来生成校验和。下面就来看看如何从
文件中生成校验和并核实该文件的完整性

```shell
# 使用下列命令计算md5sum
$ md5sum filename
68b329da9893e34099c7d8ad5cb9c940 filename 
# 如上所示，md5sum是一个长度为32个字符的十六进制串

# 我们可以将输出的校验和重定向到一个文件中，以备后用
$ md5sum filename > file_sum.md5 

# md5sum校验和计算的方法如下
$ md5sum file1 file2 file3 .. 

# 当使用多个文件时，输出中会在每行中包含单个文件的校验和
[checksum1] file1
[checksum1] file2
[checksum1] file3 

# 可以按照下面的方法用生成的文件核实数据完整性
$ md5sum -c file_sum.md5
# 这个命令会输出校验和是否匹配的信息

# 如果需要用所有的.md5信息来检查所有的文件，可以这样
$ md5sum -c *.md5 
```

SHA-1是另一种常用的校验和算法。它从给定的输入中生成一个长度为40个字符的十六进制
串。用来计算SAH-1校验和的命令是sha1sum，其用法和md5sum的类似。只需要把先前讲过的
那些命令中的md5sum改成sha1sum就行了，记住将输出文件名从file_sum.md5改为file_sum.sha1

补充内容

对于多个文件，校验和同样可以发挥作用。现在就看看如何校验并核实一组文件

对目录进行校验

```shell
# md5deep或sha1deep命令可以遍历目录树，计算其中所有文件的校验和
# 你的系统中可能并没有安装这两个程序。可以使用apt-get或yum来安装md5deep软件包
# 该命令的用法如下：
$ md5deep -rl directory_path > directory.md5
# -r使用递归遍历
# -l使用相对路径。默认情况下，md5deep会输出文件的绝对路径

# 或者也可以结合find来递归计算校验和：
$ find directory_path -type f -print0 | xargs -0 md5sum >> directory.md5 

# 用下面的命令进行核实：
$ md5sum -c directory.md5 
```

注意：尽管应用广泛，md5sum和SHA-1已不再安全，因为近年来计算能力的攀升
使其变得容易被破解。推荐使用bcrypt或sha512sum这类工具进行加密。更多
信息可参看http://codahale.com/how-to-saftyly-store-a-password/

shadow-like散列（加盐散列）

```shell
# 让我们看看如何为密码生成shadow-like加盐散列（salted hash）
# 在Linux中，用户密码是以散列值形式存储在文件/etc/shadow中的
# 该文件中典型的一行内容类似于下面这样：
test:$6$fG4eWdUi$ohTKOlEUzNk77.4S8MrYe07NTRV4M3LrJnZP9p.qc1bR5c.EcOruzPXfEu1uloBFUa18ENRH7F70zhodas3cR.:14790:0:99999:7:::

# 该行中的$6$fG4eWdUi$ohTKOlEUzNk77.4S8MrYe07NTRV4M3LrJnZP9p.qc1bR5c.EcOruzPXfEu1uloBFUa18ENRH7F70zhodas3cR是密码对应的散列值

# 有时候，我们编写的一些脚本需要编辑密码或是添加用户
# 在这种情况下，我们必须生成shadow密码字符串，向shadow文件中写入类似于上面的文本行
# 可以使用openssl来生成shadow密码

# shadow密码通常都是加盐密码（salted password）
# 所谓的“盐”（SALT）就是一个额外的字符串，起混淆的作用，使加密更加难以破解
# 盐是由一些随机位组成的，它们作为密钥生成函数的输入之一，产生密码的加盐散列
$ openssl passwd -1 -salt SALT_STRING PASSWORD
$1$SALT_STRING$323VkWkSLHuhbt1zkSsUG. 
```

关于盐的更多细节信息，请参考维基百科页面http://en.wikipedia.org/wiki/Salt_ (cryptography)

#### 加密工具与散列

加密技术主要用于防止数据遭受未经授权的访问。和上面讲的校验和算法不同，加密算法可
以无损地重构原始数据。可用的加密算法有很多，我们将讨论Linux/Unix中最常用到的那些

让我们看看crypt、gpg以及base64的用法

- crypt命令通常并没有安装在Linux系统中。它是一个简单的加密工具，相对而言不是那
  么安全。该命令从stdin接受输入，要求用户创建口令，然后将加密数据输出到 stdout：

  ```shell
  $ crypt <input_file >output_file
  # Enter passphrase:
  # 我们在命令行上提供口令：
  
  $ crypt PASSPHRASE <input_file >encrypted_file
  
  # 如果需要解密文件，可以使用：
  $ crypt PASSPHRASE -d <encrypted_file >output_file
  ```

- gpg（GNU privacy guard，GNU隐私保护）是一种应用广泛的工具，它使用加密技术来保
  护文件，以确保数据在送达目的地之前无法被读取
  
  gpg签名同样广泛用于E-mail通信中的邮件“签名”，以证明发送方的真实性
  
  ```shell
  # 用gpg加密文件：
  $ gpg -c filename
  # 命令会采用交互方式读取口令并生成filename.gpg。使用以下命令解密gpg文件：
  $ gpg filename.gpg
  # 上述命令读取口令并解密文件
  ```
  
  本书并没有涉及gpg的过多细节。如果你感兴趣，希望进一步了解，请访问
  http://en.wikipedia.org/wiki/GNU_Privacy_Guard

- Base64是一组相似的编码方案，它将二进制数据转换成以64为基数的形式（radix-64
  representation），以可读的ASCII字符串进行描述。这类编码程序可用于通过E-mail传输二
  进制数据。base64命令能够编码/解码Base64字符串。要将文件编码为Base64格式，可以
  使用

  ```shell
  $ base64 filename > outputfile
  # 或者
  $ cat file | base64 > outputfile
  # base64命令可以从stdin中读取
  
  # 解码Base64数据：
  $ base64 -d file > outputfile
  # 或者
  $ cat base64_file | base64 -d > outputfile 
  ```

#### 行排序

对文本文件进行排序是一项常见的任务。sort命令能够对文本文件和stdin进行排序。它可
以配合其他命令来生成所需要的输出。uniq经常与sort一同使用，提取不重复（或重复）的行。
这则攻略将演示sort和uniq命令的常见用法

sort和uniq命令可以从特定的文件或stdin中获取输入，并将输出写入stdout

```shell
# 1. 可以按照下面的方式排序一组文件（例如file1.txt和file2.txt）
$ sort file1.txt file2.txt > sorted.txt
# 或是
$ sort file1.txt file2.txt -o sorted.txt

# 2. 按照数字顺序排序
$ sort -n file.txt 

# 3. 按照逆序排序
$ sort -r file.txt 

# 4. 按照月份排序（依照一月、二月、三月……）
$ sort -M months.txt 

# 5. 合并两个已排序过的文件
$ sort -m sorted1 sorted2 

# 6. 找出已排序文件中不重复的行
$ sort file1.txt file2.txt | uniq 

# 7.  检查文件是否已经排序过

#!/bin/bash
#功能描述：排序
sort -C filename ;
if [ $? -eq 0 ]; then
  echo Sorted;
else
  echo Unsorted;
fi

# 将filename替换成你需要检查的文件名，然后运行该脚本
```

sort命令包含大量的选项，能够对文件数据进行各种排序。如果使用uniq命令，那sort更
是必不可少，因为前者要求输入数据必须经过排序

补充内容

1. 依据键或列排序

```shell
# 如果输入数据的格式如下，我们可以按列排序
$ cat data.txt
1	mac		2000
2	winxp	4000
3	bsd		1000
4	linux	1000 

# 有很多方法可以对这段文本排序。目前它是按照序号（第一列）来排序的。我们也可以依据第二列和第三列来排序
# -k指定了排序所依据的字符。如果是单个数字，则指的是列号
# -r告诉sort命令按照逆序进行排序。例如：

# 依据第1列，以逆序形式排序
$ sort -nrk 1 data.txt
4	linux	1000
3	bsd		1000
2	winxp	4000
1	mac		2000
# -nr表明按照数字顺序，采用逆序形式排序

# 依据第2列进行排序
$ sort -k 2 data.txt
3	bsd		1000
4	linux	1000
1	mac		2000
2	winxp	4000 
```

-k后的整数指定了文本文件中的某一列。列与列之间由空格分隔。如果需要将特定范围内的
一组字符（例如，第2列中的第4~5个字符）作为键，应该使用由点号分隔的两个整数来定义一个
字符位置，然后将该范围内的第一个字符和最后一个字符用逗号连接起来：

```shell
# 用第一个字符作为键：
$ sort -nk 1,1 data.txt

# 为了使sort的输出与以\0作为终止符的xargs命令相兼容，采用下面的命令：
$ sort -z data.txt | xargs -0
# 终止符\0用来确保安全地使用xargs命令

# 有时文本中可能会包含一些像空格之类的多余字符
# 如果需要忽略标点符号并以字典序排序，可以使用：
$ sort -bd unsorted.txt
# 其中，选项-b用于忽略文件中的前导空白行，选项-d用于指明以字典序进行排序
```

2. uniq

uniq命令可以从给定输入中（stdin或命令行参数指定的文件）找出唯一的行，报告或删除
那些重复的行

uniq只能作用于排过序的数据，因此，uniq通常都与sort命令结合使用

```shell
# 你可以按照下面的方式生成唯一的行（打印输入中的所有行，但是其中重复的行只打印一次）：
$ cat sorted.txt
bash
foss
hack
hack 

$ uniq sorted.txt
bash
foss
hack 
# 或是
$ sort unsorted.txt | uniq

# 只显示唯一的行（在输入文件中没有重复出现过的行）：
$ uniq -u sorted.txt
bash
foss 
# 或是
$ sort unsorted.txt | uniq -u

# 要统计各行在文件中出现的次数，使用下面的命令：
$ sort unsorted.txt | uniq -c
 1 bash
 1 foss
 2 hack 
 
# 找出文件中重复的行：
$ sort unsorted.txt | uniq -d
hack 

# 我们可以结合-s和-w选项来指定键：
# -s 指定跳过前N个字符
# -w 指定用于比较的最大字符数

# 这个对比键可以作为uniq操作时的索引：
$ cat data.txt
u:01:gnu
d:04:linux
u:01:bash
u:01:hack 

# 为了只测试指定的字符（忽略前两个字符，使用接下来的两个字符），我们使用-s 2跳过前两个字符，使用-w 2选项指定后续的两个字符：
$ sort data.txt | uniq -s 2 -w 2
d:04:linux
u:01:bash 
```

我们将命令输出作为xargs命令的输入时，最好为输出的各行添加一个0值字节（zero-byte）
终止符。使用uniq命令的输入作为xargs的数据源时，同样应当如此。如果没有使用0值字节终
止符，那么在默认情况下，xargs命令会用空格来分割参数。例如，来自stdin的文本行“this is
a line”会被xargs视为4个不同的参数。如果使用0值字节终止符，那么\0就被作为定界符，此时，
包含空格的行就能够被正确地解析为单个参数

```shell
# -z选项可以生成由0值字节终止的输出：
$ uniq -z file.txt

# 下面的命令将删除所有指定的文件，这些文件的名字是从files.txt中读取的：
$ uniq -z file.txt | xargs -0 rm

# 如果某个文件名出现多次，uniq命令只会将这个文件名写入stdout一次，这样就可以避免出现rm: cannot remove FILENAME: No such file or directory
```

#### 临时文件命名与随机数

shell脚本经常需要存储临时数据。最适合存储临时数据的位置是 /tmp（该目录中的内容在系
统重启后会被清空）。有两种方法可以为临时数据生成标准的文件名

mktemp命令可以为临时文件或目录创建唯一的名字

```shell
# 1. 创建临时文件
$ filename=`mktemp`
$ echo $filename
/tmp/tmp.8xvhkjF5fH
# 上面的代码创建了一个临时文件，然后打印出保存在变量filename中的文件名

# 2. 创建临时目录
$ dirname=`mktemp -d`
$ echo $dirname
tmp.NI8xzW7VRX
# 上面的代码创建了一个临时目录，然后打印出保存在变量dirname中的目录名

# 如果仅仅是想生成文件名，不希望创建实际的文件或目录，可以这样
$ tmpfile=`mktemp -u`
$ echo $tmpfile
/tmp/tmp.RsGmilRpcT
# 文件名被存储在$tmpfile中，但并没有创建对应的文件

# 基于模板创建临时文件名：
$mktemp test.XXX
test.2tc
```

mktemp命令的用法非常简单。它生成一个具有唯一名称的文件并返回该文件名（如果创建
的是目录，则返回目录名）

如果提供了定制模板，X会被随机的字符（字母或数字）替换。注意，mktemp正常工作的前
提是保证模板中至少要有3个X

#### 分割文件与数据

有时候必须把文件分割成多个更小的片段。很久以前，我们必须分割文件，才能将大量数据
放入多张软盘中。不过如今我们分割文件就是出于其他目的了，比如为提高可读性、生成日志以
及发送有大小限制的E-mail附件。在这则攻略中我们会看到如何将文件分割成不同的大小

split命令可以用来分割文件。该命令接受文件名作为参数，然后创建出一系列体积更小的
文件，其中依据字母序排在首位的那个文件对应于原始文件的第一部分，排在次位的文件对应于
原始文件的第二部分，以此类推

```shell
# 例如，通过指定分割大小，可以将100KB的文件分成一系列10KB的小文件
# 在split命令中，除了k（KB），我们还可以使用M（MB）、G（GB）、c（byte）和w（word）
$ split -b 10k data.file
$ ls
data.file xaa xab xac xad xae xaf xag xah xai xaj 
# 上面的命令将data.file分割成了10个大小为10KB的文件。这些新文件以xab、xac、xad的形式命名
# split默认使用字母后缀。如果想使用数字后缀，需要使用-d选项

# 此外，-a length可以指定后缀长度：
$ split -b 10k data.file -d -a 4
$ ls
data.file x0009 x0019 x0029 x0039 x0049 x0059 x0069 x0079 
```

补充内容

为分割后的文件指定文件名前缀

之前那些分割后的文件名都是以x作为前缀。如果要分割的文件不止一个，我们自然希望能
自己命名这些分割后的文件，这样才能够知道这些文件分别属于哪个原始文件。这可以通过提供
一个前缀作为最后一个参数来实现

```shell
# 这次我们使用split_file作为文件名前缀，重新执行上一条命令：
$ split -b 10k data.file -d -a 4 split_file
$ ls
data.file split_file0002 split_file0005 split_file0008 
strtok.c split_file0000 split_file0003 split_file0006 split_file0009 split_file0001 split_file0004 split_file0007 

# 如果不想按照数据块大小，而是根据行数来分割文件的话，可以使用 -l no_of_lines：
# 分割成多个文件，每个文件包含10行
$ split -l 10 data.file

# csplit实用工具能够基于上下文来分隔文件
# 它依据的是行计数或正则表达式。这个工具对于日志文件分割尤为有用
# 看一个日志文件示例：
$ cat server.log
SERVER-1
[connection] 192.168.0.1 success
[connection] 192.168.0.2 failed
[disconnect] 192.168.0.3 pending
[connection] 192.168.0.4 success
SERVER-2
[connection] 192.168.0.1 failed
[connection] 192.168.0.2 failed
[disconnect] 192.168.0.3 success
[connection] 192.168.0.4 failed
SERVER-3
[connection] 192.168.0.1 pending
[connection] 192.168.0.2 pending
[disconnect] 192.168.0.3 pending
[connection] 192.168.0.4 failed 

# 我们需要将这个日志文件分割成server1.log、server2.log和server3.log，这些文件的内容分别取自原文件中不同的SERVER部分
# 实现方法如下：
$ csplit server.log /SERVER/ -n 2 -s {*} -f server -b "%02d.log"
$ rm server00.log
$ ls
server01.log server02.log server03.log server.log 

# 下面是这个命令的详细说明：
# /SERVER/ 用来匹配特定行，分割过程即从此处开始
# /[REGEX]/ 用于描述文本模式。它从当前行（第一行）一直复制到（但不包括）包含SERVER的匹配行
# {*} 表示根据匹配重复执行分割操作，直到文件末尾为止。可以用{整数}的形式来指定分割执行的次数
# -s 使命令进入静默模式，不打印其他信息
# -n 指定分割后的文件名后缀的数字个数，例如01、02、03等
# -f 指定分割后的文件名前缀（在上面的例子中，server就是前缀）
# -b 指定后缀格式。例如%02d.log，类似于C语言中printf的参数格式。在这里：文件名 = 前缀 + 后缀，也就是server + %02d.log
# 因为分割后得到的第一个文件没有任何内容（匹配的单词就位于文件的第一行中），所以我们删除了server00.log
```

#### 根据扩展名切分文件名









#### 多个文件的重命名与移动





#### 拼写检查与词典操作





#### 交互输入自动化





#### 利用并行进程加速命令执行






#### 检查目录以及其中的文件与子目录
















